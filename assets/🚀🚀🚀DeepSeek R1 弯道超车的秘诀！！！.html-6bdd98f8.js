import{_ as l}from"./plugin-vue_export-helper-c27b6911.js";import{r as i,o as r,c as m,f as p,a as s,b as t,e as n}from"./app-90cb810c.js";const o={},c={style:{"text-align":"center"}},g={href:"https://huggingface.co/Qwen/Qwen2.5-Math-1.5B",target:"_blank",rel:"noopener noreferrer"},h={style:{"text-align":"center"}},d={href:"https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",target:"_blank",rel:"noopener noreferrer"},y={style:{"text-align":"center"}},u={href:"https://huggingface.co/Qwen/Qwen2.5-Math-7B",target:"_blank",rel:"noopener noreferrer"},b={style:{"text-align":"center"}},f={href:"https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",target:"_blank",rel:"noopener noreferrer"},v={style:{"text-align":"center"}},k={href:"https://huggingface.co/meta-llama/Llama-3.1-8B",target:"_blank",rel:"noopener noreferrer"},x={style:{"text-align":"center"}},w={href:"https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B",target:"_blank",rel:"noopener noreferrer"},_={style:{"text-align":"center"}},D={href:"https://huggingface.co/Qwen/Qwen2.5-14B",target:"_blank",rel:"noopener noreferrer"},L={style:{"text-align":"center"}},z={href:"https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",target:"_blank",rel:"noopener noreferrer"},B={style:{"text-align":"center"}},M={href:"https://huggingface.co/Qwen/Qwen2.5-32B",target:"_blank",rel:"noopener noreferrer"},j={style:{"text-align":"center"}},S={href:"https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",target:"_blank",rel:"noopener noreferrer"},R={style:{"text-align":"center"}},Q={href:"https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct",target:"_blank",rel:"noopener noreferrer"},T={style:{"text-align":"center"}},I={href:"https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-70B",target:"_blank",rel:"noopener noreferrer"};function C(E,a){const e=i("ExternalLinkIcon");return r(),m("div",null,[a[19]||(a[19]=p(`<h3 id="前言" tabindex="-1"><a class="header-anchor" href="#前言" aria-hidden="true">#</a> 前言</h3><p>整个假期不管是视频还是公众号，都被<code>Deepseek R1</code>刷屏了，作为国人看到自己国家的大模型如此披荆斩棘，所向披靡，实在令人扬眉吐气，中国的国运到了啊！</p><p>最令人振奋的是，<code>Deepseek R1</code>训练成本仅几百万美元，而<code>chatgpt-4o</code>的训练成本约一亿美元！</p><p>所以，今天我们来看看 <code>DeepSeek R1</code> 弯道超车的秘诀！！！</p><blockquote><p>文章同步在公众号：萌萌哒草头将军，欢迎关注</p></blockquote><h3 id="蒸馏模型-大白话版本" tabindex="-1"><a class="header-anchor" href="#蒸馏模型-大白话版本" aria-hidden="true">#</a> 蒸馏模型（大白话版本）</h3><p>阅读官方文档时发现提到了蒸馏模型</p><p>蒸馏模型是一种利用 <code>知识蒸馏（Knowledge Distillation）</code>技术从更大的教师模型（千亿参数规模的<code>LLM</code>）中迁移核心能力后得到的轻量化模型（学生模型）。</p><p>大白话就这么简单，专业解释可以看文末！</p><p>这类模型可以在保持高性能的同时显著降低计算成本和部署门槛。</p><table><thead><tr><th>模型</th><th>参数量</th><th>单次推理耗时（GPU）</th><th>内存占用</th></tr></thead><tbody><tr><td>教师模型（原始）</td><td>100B</td><td>5000ms</td><td>80GB</td></tr><tr><td>DeepSeek-R1</td><td>10B</td><td>300ms</td><td>8GB</td></tr></tbody></table><p>我们举个例子，</p><p>当你问大模型：鸡兔同笼，共有头 10 个，脚 28 只，问鸡和兔各多少只？</p><p>教师模型会这么推理：</p><pre><code>步骤1：设鸡有x只，兔有y只。
步骤2：根据头数，x + y = 10。
步骤3：根据脚数，2x + 4y = 28。
步骤4：解方程组得x=6，y=4。
答案：鸡6只，兔4只。
</code></pre><p>蒸馏模型会模仿教师模型的推理思路，并且通过参数微调使结果输出一致：</p><pre><code>步骤1：总头数10，假设全是鸡，脚数为20。
步骤2：实际脚数28，多出8只脚。
步骤3：每只兔比鸡多2只脚，8÷2=4，因此兔有4只。
步骤4：鸡的数量为10-4=6只。
答案：鸡6只，兔4只。
</code></pre><p>简单地说，蒸馏模型的作用如下三点：</p><ol><li>压缩模型：减少参数量和计算成本，适合边缘部署；</li><li>保留性能：继承教师模型的逻辑推理、泛化能力，性能损失小；</li><li>提升效率：降低推理延迟和资源消耗，扩展至移动端、实时服务等场景。</li></ol><p><code>Deepseek R1</code>是基于一种更加复杂的教师模型提炼出来的推理模型，而下面这些是基于<code>Deepseek R1</code>和其他模型进一步提炼出来的学生模型。</p>`,20)),s("table",null,[a[18]||(a[18]=s("thead",null,[s("tr",null,[s("th",{style:{"text-align":"center"}},[s("strong",null,"Model")]),s("th",{style:{"text-align":"center"}},[s("strong",null,"Base Model")]),s("th",{style:{"text-align":"center"}},[s("strong",null,"Download")])])],-1)),s("tbody",null,[s("tr",null,[a[2]||(a[2]=s("td",{style:{"text-align":"center"}},"DeepSeek-R1-Distill-Qwen-1.5B",-1)),s("td",c,[s("a",g,[a[0]||(a[0]=t("Qwen2.5-Math-1.5B")),n(e)])]),s("td",h,[s("a",d,[a[1]||(a[1]=t("🤗 HuggingFace")),n(e)])])]),s("tr",null,[a[5]||(a[5]=s("td",{style:{"text-align":"center"}},"DeepSeek-R1-Distill-Qwen-7B",-1)),s("td",y,[s("a",u,[a[3]||(a[3]=t("Qwen2.5-Math-7B")),n(e)])]),s("td",b,[s("a",f,[a[4]||(a[4]=t("🤗 HuggingFace")),n(e)])])]),s("tr",null,[a[8]||(a[8]=s("td",{style:{"text-align":"center"}},"DeepSeek-R1-Distill-Llama-8B",-1)),s("td",v,[s("a",k,[a[6]||(a[6]=t("Llama-3.1-8B")),n(e)])]),s("td",x,[s("a",w,[a[7]||(a[7]=t("🤗 HuggingFace")),n(e)])])]),s("tr",null,[a[11]||(a[11]=s("td",{style:{"text-align":"center"}},"DeepSeek-R1-Distill-Qwen-14B",-1)),s("td",_,[s("a",D,[a[9]||(a[9]=t("Qwen2.5-14B")),n(e)])]),s("td",L,[s("a",z,[a[10]||(a[10]=t("🤗 HuggingFace")),n(e)])])]),s("tr",null,[a[14]||(a[14]=s("td",{style:{"text-align":"center"}},"DeepSeek-R1-Distill-Qwen-32B",-1)),s("td",B,[s("a",M,[a[12]||(a[12]=t("Qwen2.5-32B")),n(e)])]),s("td",j,[s("a",S,[a[13]||(a[13]=t("🤗 HuggingFace")),n(e)])])]),s("tr",null,[a[17]||(a[17]=s("td",{style:{"text-align":"center"}},"DeepSeek-R1-Distill-Llama-70B",-1)),s("td",R,[s("a",Q,[a[15]||(a[15]=t("Llama-3.3-70B-Instruct")),n(e)])]),s("td",T,[s("a",I,[a[16]||(a[16]=t("🤗 HuggingFace")),n(e)])])])])]),a[20]||(a[20]=p(`<h3 id="📌-蒸馏模型的关键概念-专业解释" tabindex="-1"><a class="header-anchor" href="#📌-蒸馏模型的关键概念-专业解释" aria-hidden="true">#</a> 📌 蒸馏模型的关键概念（专业解释）</h3><p>相信下面的专业解释会令人头大，所以我放在了文末，感兴趣的小伙伴可以继续阅读！</p><blockquote><p>知识蒸馏（Knowledge Distillation）通过教师模型生成的 <strong>软目标（Soft Targets）</strong>，结合 <strong>温度参数（Temperature, T）</strong> 平滑概率分布，并使用 <strong>交叉熵损失（CE Loss）和 KL 散度（KL Loss）</strong> 优化学生模型，使其在保持较小规模的同时，高效学习教师模型的知识。</p></blockquote><h4 id="什么是软目标-soft-targets" tabindex="-1"><a class="header-anchor" href="#什么是软目标-soft-targets" aria-hidden="true">#</a> 什么是<strong>软目标（Soft Targets）</strong></h4><p>传统的神经网络训练使用<strong>硬标签（Hard Labels）</strong>，比如手写数字识别里<code>“8”</code>就是 <code>100%</code> 属于 <code>“8”</code>类别，其他类别全是<code>0%</code>。</p><p>但教师模型的输出概率分布更丰富，比如 <code>“8”</code> 可能有 <code>80%</code> 概率属于 <code>“8”</code>，<code>10%</code> 概率属于 <code>“3”</code>，<code>5%</code> 属于 <code>“0”</code>。这种信息能帮助学生模型更好地学习类别间的关系。</p><h4 id="什么是温度参数-temperature-t" tabindex="-1"><a class="header-anchor" href="#什么是温度参数-temperature-t" aria-hidden="true">#</a> 什么是<strong>温度参数（Temperature, T）</strong></h4><p>在蒸馏过程中，我们可以调整一个<strong>温度系数</strong> 来平滑教师模型的输出概率：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>p</mi><mi>i</mi></msub><mo>=</mo><mfrac><msup><mi>e</mi><mrow><msub><mi>z</mi><mi>i</mi></msub><mi mathvariant="normal">/</mi><mi>T</mi></mrow></msup><mrow><munder><mo>∑</mo><mi>j</mi></munder><msup><mi>e</mi><mrow><msub><mi>z</mi><mi>j</mi></msub><mi mathvariant="normal">/</mi><mi>T</mi></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex"> p_i = \\frac{e^{z_i / T}}{\\sum_j e^{z_j / T}} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.7209em;vertical-align:-1.1559em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.565em;"><span style="top:-2.2799em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.162em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4358em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8301em;"><span style="top:-3.0051em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.044em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em;"><span></span></span></span></span></span></span><span class="mord mtight">/</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.044em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mord mtight">/</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.1559em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p>对应的概率分布图如下：</p><figure><img src="https://p0-xtjj-private.juejin.cn/tos-cn-i-73owjymdk6/260150327bc2479180ad2608c198fa3e~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg6JCM6JCM5ZOS6I2J5aS05bCG5Yab:q75.awebp?policy=eyJ2bSI6MywidWlkIjoiMTExNjc1OTU0MzI2MDcyNyJ9&amp;rk3s=f64ab15b&amp;x-orig-authkey=f32326d3454f2ac7e96d3d06cdbb035152127018&amp;x-orig-expires=1739447471&amp;x-orig-sign=JYzMqbMb9CjiVPoMBmMwR8lzs9w%3D" alt="image.png" tabindex="0" loading="lazy"><figcaption>image.png</figcaption></figure><p><strong>较高的 T 值</strong> 会让概率分布变得更平滑，强调类别间的相似性，让学生模型学习到更丰富的信息。</p><h4 id="什么是损失函数-distillation-loss" tabindex="-1"><a class="header-anchor" href="#什么是损失函数-distillation-loss" aria-hidden="true">#</a> 什么是<strong>损失函数（Distillation Loss）</strong></h4><p>知识蒸馏的损失通常由两个部分组成：</p><ul><li><strong>交叉熵损失（CE Loss）</strong> ：确保学生模型正确分类</li><li><strong>KL 散度（Kullback-Leibler Divergence）</strong> ：让学生模型的输出模仿教师模型</li></ul><p>总体损失函数<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>：</mtext><mi>L</mi><mo>=</mo><mi>α</mi><mo>⋅</mo><msub><mi>L</mi><mrow><mi>C</mi><mi>E</mi></mrow></msub><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>α</mi><mo stretchy="false">)</mo><mo>⋅</mo><msub><mi>L</mi><mrow><mi>K</mi><mi>L</mi></mrow></msub></mrow><annotation encoding="application/x-tex">：L = \\alpha \\cdot L_{CE} + (1 - \\alpha) \\cdot L_{KL}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord cjk_fallback">：</span><span class="mord mathnormal">L</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.4445em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">CE</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></p><p>其中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span>是权重系数，平衡两种损失的影响，下面是损失函数对应的损失曲线：</p><figure><img src="https://p0-xtjj-private.juejin.cn/tos-cn-i-73owjymdk6/1268566760a541cf86a4f7874141e5fd~tplv-73owjymdk6-jj-mark-v1:0:0:0:0:5o6Y6YeR5oqA5pyv56S-5Yy6IEAg6JCM6JCM5ZOS6I2J5aS05bCG5Yab:q75.awebp?policy=eyJ2bSI6MywidWlkIjoiMTExNjc1OTU0MzI2MDcyNyJ9&amp;rk3s=f64ab15b&amp;x-orig-authkey=f32326d3454f2ac7e96d3d06cdbb035152127018&amp;x-orig-expires=1739447471&amp;x-orig-sign=qbQxByWxW4Vw4iwvLOFcKj%2FALW8%3D" alt="image.png" tabindex="0" loading="lazy"><figcaption>image.png</figcaption></figure><p>我们再来一个简单的例子：识别图像里的动物是猫还是狗。</p><p>教师模型给出的结果可能如下：</p><pre><code>步骤1: 训练教师模型，准确率：95%，给出概率分布：猫：0.9, 狗：0.1
步骤2: 获取软目标，引入温度参数T，平滑处理之后：猫：0.8, 狗：0.2
步骤3: 训练学生模型，将学生模型的输出与真实标签进行比较，计算交叉熵损失。
    同时，我们也计算学生模型输出与教师模型的软目标之间的KL散度。
    KL散度衡量两个概率分布之间的差异，帮助学生模型学习教师模型的知识。
    得到学生模型的损失函数。
步骤 4: 微调学生模型：通过反向传播更新学生模型的权重，拟合教师模型的软目标。
</code></pre><p>由此得到一个学生模型，虽然它的规模更小，但是的性能得到了提升，准确率可以达到<code>90%</code></p><h3 id="总结" tabindex="-1"><a class="header-anchor" href="#总结" aria-hidden="true">#</a> 总结</h3><p><code>DeepSeek-R1</code> 的成功证明，通过技术创新（如知识蒸馏、领域专注和高效架构设计），可以在低成本下实现高性能，</p><p><code>DeepSeek-R1</code>不仅推动大模型行业从“堆参数”转向“精准优化”，也为 <code>AI</code> 落地提供更高效的路径!</p>`,25))])}const q=l(o,[["render",C],["__file","🚀🚀🚀DeepSeek R1 弯道超车的秘诀！！！.html.vue"]]);export{q as default};
